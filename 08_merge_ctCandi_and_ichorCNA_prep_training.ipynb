{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candi read files: 275\n",
      "Number of classification files: 275\n",
      "Data exists!\n",
      "Number of candi read files: 275\n",
      "Number of classification files: 275\n",
      "Data exists!\n",
      "Number of candi read files: 275\n",
      "Number of classification files: 275\n",
      "Data exists!\n",
      "Number of candi read files: 275\n",
      "Number of classification files: 275\n",
      "Data exists!\n",
      "Number of candi read files: 275\n",
      "Number of classification files: 275\n",
      "Data exists!\n",
      "Number of candi read files: 427\n",
      "Number of classification files: 427\n",
      "Data exists!\n",
      "Number of candi read files: 427\n",
      "Number of classification files: 427\n",
      "Data exists!\n",
      "Number of candi read files: 427\n",
      "Number of classification files: 427\n",
      "Data exists!\n",
      "Number of candi read files: 427\n",
      "Number of classification files: 427\n",
      "Data exists!\n",
      "Number of candi read files: 427\n",
      "Number of classification files: 427\n",
      "Data exists!\n",
      "Number of candi read files: 4956\n",
      "Number of classification files: 4956\n",
      "Data exists!\n",
      "Number of candi read files: 4956\n",
      "Number of classification files: 4956\n",
      "Data exists!\n",
      "Number of candi read files: 4956\n",
      "Number of classification files: 4956\n",
      "Data exists!\n",
      "Number of candi read files: 4956\n",
      "Number of classification files: 4956\n",
      "Data exists!\n",
      "Number of candi read files: 4956\n",
      "Number of classification files: 4956\n",
      "Data exists!\n",
      "Number of candi read files: 900\n",
      "Number of classification files: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [02:32<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candi read files: 900\n",
      "Number of classification files: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [02:12<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candi read files: 900\n",
      "Number of classification files: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [02:08<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candi read files: 900\n",
      "Number of classification files: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [02:15<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candi read files: 900\n",
      "Number of classification files: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [02:07<00:00,  7.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "from dataset_paths import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "output_version = \"20241229\"\n",
    "outdir = \"/media/hieunguyen/HNSD_mini/outdir\"\n",
    "\n",
    "mode = \"all\"\n",
    "PROJECT = \"combine_ctcandi_ichorcna\"\n",
    "\n",
    "for dataset_name in [\"VALIDATION\", \"LOD\", \"SPIKE_IN\", \"CONTROL\"]:\n",
    "\n",
    "    for input_cancer_class in [\"CRC\", \"Liver\", \"Lung\", \"Breast\", \"pan_cancer\"]:\n",
    "        metadata = pd.read_csv(f\"./metadata/{dataset_name}.csv\")\n",
    "        path_to_main_output = os.path.join(outdir, PROJECT, output_version, dataset_name)\n",
    "        path_to_07_output = os.path.join(path_to_main_output, f\"07_output_{mode}\", input_cancer_class)\n",
    "        path_to_08_output = os.path.join(path_to_main_output, f\"08_output_{mode}\", input_cancer_class)\n",
    "        os.system(f\"mkdir -p {path_to_08_output}\")\n",
    "        all_read_classification_files = [item for item in pathlib.Path(path_to_07_output).glob(\"*.raw.read_classification.csv\")]\n",
    "        all_candi_read_files = [item for item in pathlib.Path(path_to_07_output).glob(\"*candi_reads.csv\")]\n",
    "\n",
    "        if dataset_name == \"LOD\":\n",
    "            convert_ratio = {\n",
    "            '50' : 0.5, \n",
    "            '100': 1, \n",
    "            '0.5': 0.005, \n",
    "            '25': 0.25, \n",
    "            '15': 0.15, \n",
    "            '5': 0.05, \n",
    "            '1': 0.01, \n",
    "            'HC': 0\n",
    "            }\n",
    "            metadata = metadata[metadata[\"Sample\"].duplicated() == False]\n",
    "            metadata[\"SampleID\"] = metadata[\"Sample\"].values\n",
    "            metadata.columns = [\"ichorCNA\" if item == \"Actual tumor_fraction_ichorCNA\" else item for item in metadata.columns]\n",
    "            metadata[\"spike_in_ratio\"] = metadata[\"spike-in\"].apply(lambda x: convert_ratio[x])\n",
    "            metadata['Label'] = metadata[\"LABEL\"].apply(lambda x: \"CRC\" if x == \"Colorectal cancer\" else x.split(\" \")[0])\n",
    "            metadata[\"spike_in_label\"] = metadata[\"Simulated TF\"].apply(lambda x: \"Control\" if x == \"Healthy-control\" else input_cancer_class)\n",
    "            metadata[\"Label\"] = metadata[[\"Label\", \"spike_in_label\"]].apply(lambda x: x[0] if x[1] != \"Control\" else \"Control\", axis = 1)\n",
    "            metadata = metadata[[\"SampleID\", \"ichorCNA\", \"spike_in_ratio\", \"Label\"]]\n",
    "        elif dataset_name == \"VALIDATION\":\n",
    "            metadata = metadata[[\"SampleID\", \"ichorCNA\"]]\n",
    "            all_candi_read_files = [item for item in all_candi_read_files if item.name.replace(\".candi_reads.csv\", \"\") in metadata[\"SampleID\"].unique()]\n",
    "            all_read_classification_files = [item for item in all_read_classification_files if item.name.replace(\".raw.read_classification.csv\", \"\") in metadata[\"SampleID\"].unique()]\n",
    "        elif dataset_name == \"SPIKE_IN\":\n",
    "            metadata = metadata[[\"SampleID\", \"Spike_in_label\", \"Spike_in_ratio\", \"ichorCNA\"]]\n",
    "            metadata[\"Spike_in_ratio\"] = metadata[\"Spike_in_ratio\"].apply(lambda x: x/100)\n",
    "            metadata.columns = [\"SampleID\", \"Label\", \"spike_in_ratio\", \"ichorCNA\"]\n",
    "            metadata = metadata[[\"SampleID\", \"ichorCNA\", \"spike_in_ratio\", \"Label\"]]\n",
    "        elif dataset_name in [\"REPORT4\", \"CONTROL\"]:\n",
    "            metadata = metadata[[\"SampleID\", \"ichorCNA\", \"Label\"]]\n",
    "            metadata = metadata[metadata[\"ichorCNA\"].isna() == False]\n",
    "\n",
    "        print(f\"Number of candi read files: {len(all_candi_read_files)}\")\n",
    "        print(f\"Number of classification files: {len(all_read_classification_files)}\")\n",
    "\n",
    "        if os.path.isfile(os.path.join(path_to_08_output, \"feature.csv\")) == False:\n",
    "            fulldf = pd.DataFrame()\n",
    "            for i in tqdm(range(len(all_candi_read_files))):\n",
    "                tmp_readdf = pd.read_csv(all_read_classification_files[i], index_col = [0])\n",
    "                tmp_candidf = pd.read_csv(all_candi_read_files[i], index_col = [0])\n",
    "                sampleid = all_candi_read_files[i].name.replace(\".candi_reads.csv\", \"\")\n",
    "                raw_count = tmp_readdf.shape[0]\n",
    "                in_read_count = tmp_readdf[tmp_readdf[\"read_overlap_rate\"] == \"in\"].shape[0]\n",
    "                mean_candi_reads = tmp_candidf.candi_reads.mean()\n",
    "                ratio_raw = mean_candi_reads/raw_count\n",
    "                ratio_in_read = mean_candi_reads/in_read_count\n",
    "                tmpdf = pd.DataFrame({\"SampleID\": sampleid, \n",
    "                                    \"raw_count\": raw_count, \n",
    "                                    \"in_read_count\": in_read_count, \n",
    "                                    \"mean_candi_reads\": mean_candi_reads,\n",
    "                                    \"ratio_raw\": ratio_raw,\n",
    "                                    \"ratio_in_read\": ratio_in_read}, index = [0])\n",
    "\n",
    "                fulldf = pd.concat([fulldf, tmpdf], axis = 0)\n",
    "            fulldf = fulldf.merge(metadata, right_on = \"SampleID\", left_on = \"SampleID\")\n",
    "            fulldf.to_csv(os.path.join(path_to_08_output, \"feature.csv\"))\n",
    "        else:\n",
    "            print(f\"Data exists!\")\n",
    "            fulldf = pd.read_csv(os.path.join(path_to_08_output, \"feature.csv\"), index_col = [0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
