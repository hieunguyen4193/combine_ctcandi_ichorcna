{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candi read files: 275\n",
      "Number of classification files: 275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–Ž         | 10/275 [00:02<01:37,  2.73it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "from dataset_paths import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "output_version = \"20241229\"\n",
    "outdir = \"/media/hieunguyen/HNSD_mini/outdir\"\n",
    "dataset_name = \"VALIDATION\"\n",
    "mode = \"all\"\n",
    "PROJECT = \"combine_ctcandi_ichorcna\"\n",
    "\n",
    "for input_cancer_class in [\"CRC\", \"Liver\", \"Lung\", \"Breast\", \"pan_cancer\"]:\n",
    "    path_to_main_output = os.path.join(outdir, PROJECT, output_version, dataset_name)\n",
    "    path_to_07_output = os.path.join(path_to_main_output, f\"07_output_{mode}\", input_cancer_class)\n",
    "    path_to_08_output = os.path.join(path_to_main_output, f\"08_output_{mode}\", input_cancer_class)\n",
    "    os.system(f\"mkdir -p {path_to_08_output}\")\n",
    "    all_read_classification_files = [item for item in pathlib.Path(path_to_07_output).glob(\"*.raw.read_classification.csv\")]\n",
    "    all_candi_read_files = [item for item in pathlib.Path(path_to_07_output).glob(\"*candi_reads.csv\")]\n",
    "\n",
    "    metadata = pd.read_csv(f\"./metadata/{dataset_name}.csv\")\n",
    "    if dataset_name == \"LOD\":\n",
    "        metadata = metadata[metadata[\"Sample\"].duplicated() == False]\n",
    "        merge_samples = [item for item in all_candi_read_files if item.name.replace(\".candi_reads.csv\", \"\") in metadata[\"SampleID\"].unique()]\n",
    "    elif dataset_name == \"VALIDATION\":\n",
    "        metadata = metadata[[\"SampleID\", \"ichorCNA\"]]\n",
    "        all_candi_read_files = [item for item in all_candi_read_files if item.name.replace(\".candi_reads.csv\", \"\") in metadata[\"SampleID\"].unique()]\n",
    "        all_read_classification_files = [item for item in all_read_classification_files if item.name.replace(\".raw.read_classification.csv\", \"\") in metadata[\"SampleID\"].unique()]\n",
    "    print(f\"Number of candi read files: {len(all_candi_read_files)}\")\n",
    "    print(f\"Number of classification files: {len(all_read_classification_files)}\")\n",
    "\n",
    "    if os.path.isfile(os.path.join(path_to_08_output, \"feature.csv\")) == False:\n",
    "        fulldf = pd.DataFrame()\n",
    "        for i in tqdm(range(len(all_candi_read_files))):\n",
    "            tmp_readdf = pd.read_csv(all_read_classification_files[i], index_col = [0])\n",
    "            tmp_candidf = pd.read_csv(all_candi_read_files[i], index_col = [0])\n",
    "            sampleid = all_candi_read_files[i].name.replace(\".candi_reads.csv\", \"\")\n",
    "            raw_count = tmp_readdf.shape[0]\n",
    "            in_read_count = tmp_readdf[tmp_readdf[\"read_overlap_rate\"] == \"in\"].shape[0]\n",
    "            mean_candi_reads = tmp_candidf.candi_reads.mean()\n",
    "            ratio_raw = mean_candi_reads/raw_count\n",
    "            ratio_in_read = mean_candi_reads/in_read_count\n",
    "            tmpdf = pd.DataFrame({\"SampleID\": sampleid, \n",
    "                                \"raw_count\": raw_count, \n",
    "                                \"in_read_count\": in_read_count, \n",
    "                                \"mean_candi_reads\": mean_candi_reads,\n",
    "                                \"ratio_raw\": ratio_raw,\n",
    "                                \"ratio_in_read\": ratio_in_read}, index = [0])\n",
    "\n",
    "            fulldf = pd.concat([fulldf, tmpdf], axis = 0)\n",
    "        fulldf.to_csv(os.path.join(path_to_08_output, \"feature.csv\"))\n",
    "    else:\n",
    "        fulldf = pd.read_csv(os.path.join(path_to_08_output, \"feature.csv\"), index_col = [0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
